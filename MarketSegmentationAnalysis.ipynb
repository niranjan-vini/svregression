{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/niranjan-vini/svregression/blob/main/MarketSegmentationAnalysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Packages and Read the Dataset"
      ],
      "metadata": {
        "id": "aJV-h-KlyuO1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import adjusted_rand_score\n",
        "from scipy.cluster.hierarchy import linkage, dendrogram\n",
        "from statsmodels.graphics.mosaicplot import mosaic\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree"
      ],
      "metadata": {
        "id": "e6Sim1ltytE4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y1XO7lXzbZrm",
        "outputId": "41a24d02-2a07-41a9-849a-de4f0d1d86e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/mcdonalds.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2-4183032239.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load your dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/mcdonalds.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/mcdonalds.csv'"
          ]
        }
      ],
      "source": [
        "# Load your dataset\n",
        "\n",
        "df = pd.read_csv('mcdonalds.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initial Data Exploration"
      ],
      "metadata": {
        "id": "9yy1Jt2Ny7M4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# View basic info\n",
        "print(df.shape)\n",
        "print(df.columns)\n",
        "df.head(3)"
      ],
      "metadata": {
        "id": "23ab-hQskXQR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Preparation and PCA (Perceptual Map)"
      ],
      "metadata": {
        "id": "xkcMxUvIzDvs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Convert Yes/No to binary 1/0 for the first 11 segmentation variables\n",
        "MD_x = df.iloc[:, :11].apply(lambda col: col.map(lambda x: 1 if x == \"Yes\" else 0))\n",
        "\n",
        "# Step 2: Perform PCA without standardization (as variables are already binary)\n",
        "pca = PCA()\n",
        "pca_coords = pca.fit_transform(MD_x)\n",
        "\n",
        "# Step 3: Get PCA summary (standard deviations, variance explained, cumulative)\n",
        "explained_variance = pca.explained_variance_ratio_\n",
        "cumulative_variance = np.cumsum(explained_variance)\n",
        "std_devs = np.sqrt(pca.explained_variance_)\n",
        "\n",
        "# Print PCA summary (like R's summary(MD.pca))\n",
        "print(\"Importance of components:\\n\")\n",
        "print(f\"{'PC':<5}{'Std Dev':<10}{'Var Explained':<18}{'Cumulative':<10}\")\n",
        "for i in range(len(std_devs)):\n",
        "    print(f\"PC{i+1:<3} {std_devs[i]:<10.4f} {explained_variance[i]:<18.4f} {cumulative_variance[i]:<10.4f}\")\n",
        "\n",
        "# Step 4: Print loadings (PCA components, like R's print(MD.pca))\n",
        "loadings = pd.DataFrame(\n",
        "    data=pca.components_.T,\n",
        "    columns=[f\"PC{i+1}\" for i in range(pca.n_components_)],\n",
        "    index=MD_x.columns\n",
        ")\n",
        "print(\"\\nPCA Loadings (first few PCs):\")\n",
        "print(loadings.iloc[:, :7].round(3))  # Display first 7 PCs\n",
        "\n",
        "# Step 5: Perceptual Map (Figure A.1) – Plot consumers and attribute arrows\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "\n",
        "# Plot projected respondents in PC1-PC2 space (grey dots)\n",
        "ax.scatter(pca_coords[:, 0], pca_coords[:, 1], alpha=0.5, color='grey', label='Respondents')\n",
        "\n",
        "# Plot arrows for each variable (attribute)\n",
        "for i, var in enumerate(MD_x.columns):\n",
        "    ax.arrow(0, 0, pca.components_[0, i]*2, pca.components_[1, i]*2,\n",
        "             color='red', alpha=0.8, head_width=0.03)\n",
        "    ax.text(pca.components_[0, i]*2.3, pca.components_[1, i]*2.3,\n",
        "            var, color='darkred', ha='center', va='center', fontsize=9)\n",
        "\n",
        "# Formatting the plot\n",
        "ax.set_title('A.1 – PCA Perceptual Map of McDonald\\'s Attributes')\n",
        "ax.set_xlabel(\"PC1\")\n",
        "ax.set_ylabel(\"PC2\")\n",
        "ax.axhline(0, color='black', lw=0.5)\n",
        "ax.axvline(0, color='black', lw=0.5)\n",
        "ax.grid(True)\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "id": "NLiH0sdQzDeT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extracting Segments using K-Means"
      ],
      "metadata": {
        "id": "v7bvT3hGzTLu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "k_values = range(2, 9)\n",
        "wcss = []  # Within-cluster sum of squares (inertia)\n",
        "labels_dict = {}\n",
        "\n",
        "for k in k_values:\n",
        "    kmeans = KMeans(n_clusters=k, n_init=10, random_state=1234)\n",
        "    kmeans.fit(MD_x)\n",
        "    wcss.append(kmeans.inertia_)\n",
        "    labels_dict[k] = kmeans.labels_"
      ],
      "metadata": {
        "id": "nTkb52TrnSM6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.bar(k_values, wcss, color='lightblue', edgecolor='black')\n",
        "plt.title(\"A.2 – Scree Plot\")\n",
        "plt.xlabel(\"Number of Segments\")\n",
        "plt.ylabel(\"Sum of Within-Cluster Distances\")\n",
        "plt.grid(axis='y')\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "id": "cbJgXW09nqkV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Global Stability Analysis using Bootstrapped Adjusted Rand Index (ARI)"
      ],
      "metadata": {
        "id": "RhjTvcTB2BSW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import resample\n",
        "from sklearn.metrics import adjusted_rand_score\n",
        "\n",
        "# For each k, store 100 bootstrapped ARI values\n",
        "boot_ari_scores = {k: [] for k in k_values}\n",
        "\n",
        "# Outer loop over cluster sizes\n",
        "for k in k_values:\n",
        "    original_model = KMeans(n_clusters=k, n_init=10, random_state=42).fit(MD_x)\n",
        "    original_labels = original_model.labels_\n",
        "\n",
        "    # Perform 100 bootstrap samples\n",
        "    for i in range(100):\n",
        "        bootstrap_sample = resample(MD_x, replace=True, random_state=1000+i)\n",
        "        bootstrap_model = KMeans(n_clusters=k, n_init=10, random_state=1000+i).fit(bootstrap_sample)\n",
        "\n",
        "        # Predict labels on the original data using the bootstrap model\n",
        "        boot_labels = bootstrap_model.predict(MD_x)\n",
        "\n",
        "        # Compute ARI between original clustering and bootstrap prediction\n",
        "        ari = adjusted_rand_score(original_labels, boot_labels)\n",
        "        boot_ari_scores[k].append(ari)"
      ],
      "metadata": {
        "id": "HT1qYg6UnuUL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(9, 5))\n",
        "plt.boxplot([boot_ari_scores[k] for k in k_values], labels=k_values)\n",
        "plt.title(\"A.3 – Global Stability (Bootstrapped ARI)\")\n",
        "plt.xlabel(\"Number of Segments\")\n",
        "plt.ylabel(\"Adjusted Rand Index\")\n",
        "plt.grid(axis='y')\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "id": "20vNoLL-n3e8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gorge Plot: Segment Centers for k = 4 Clusters"
      ],
      "metadata": {
        "id": "eL72Mkcs2Ow_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Re-run k-means with 4 clusters\n",
        "kmeans_k4 = KMeans(n_clusters=4, n_init=10, random_state=42).fit(MD_x)\n",
        "df['cluster_k4'] = kmeans_k4.labels_\n",
        "\n",
        "# Compute mean (i.e., segment center) for each attribute by cluster\n",
        "cluster_means = MD_x.copy()\n",
        "cluster_means['cluster'] = df['cluster_k4']\n",
        "means = cluster_means.groupby('cluster').mean().T  # Transpose for attributes on x-axis\n",
        "\n",
        "# Bar chart like gorge plot\n",
        "means.plot(kind='bar', figsize=(12, 6), width=0.8)\n",
        "plt.title(\"A.4 – Gorge Plot (Segment Centers, k = 4)\")\n",
        "plt.xlabel(\"Attribute\")\n",
        "plt.ylabel(\"Average Value (0–1)\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend(title=\"Segment\")\n",
        "plt.grid(axis='y')\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "id": "dXHzNhk9oBvq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Segment-Level Stability Across Solutions (SLSA)"
      ],
      "metadata": {
        "id": "GokWK6_k2YA4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "slsa_scores = []\n",
        "k_values = range(2, 9)\n",
        "\n",
        "for k in k_values:\n",
        "    labels = []\n",
        "    for seed in range(5):  # 5 random seeds for replication\n",
        "        km = KMeans(n_clusters=k, n_init=1, random_state=seed).fit(MD_x)\n",
        "        labels.append(km.labels_)\n",
        "\n",
        "    # Use the first run as reference, compute average ARI vs others\n",
        "    ref = labels[0]\n",
        "    mean_ari = np.mean([adjusted_rand_score(ref, lab) for lab in labels[1:]])\n",
        "    slsa_scores.append(mean_ari)\n",
        "\n",
        "# Plot SLSA\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(k_values, slsa_scores, marker='o', color='green')\n",
        "plt.title(\"A.5 – Segment Level Stability Across Solutions (SLSA)\")\n",
        "plt.xlabel(\"Number of Segments\")\n",
        "plt.ylabel(\"Avg Adjusted Rand Index (Stability)\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "id": "vXwYnBYpoWp1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Segment-Level Stability Within Solutions (SLSW, k = 4)"
      ],
      "metadata": {
        "id": "6DIBDUlj2lFt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import resample\n",
        "\n",
        "segment_stability = {i: [] for i in range(4)}  # 4 segments\n",
        "\n",
        "# Reference model on full data\n",
        "ref_model = KMeans(n_clusters=4, n_init=10, random_state=42).fit(MD_x)\n",
        "ref_labels = ref_model.labels_\n",
        "\n",
        "# Bootstrap and compare labels\n",
        "for i in range(10):  # Try 10 bootstrap samples\n",
        "    boot = resample(MD_x, replace=True, random_state=100 + i)\n",
        "    boot_model = KMeans(n_clusters=4, n_init=10, random_state=100 + i).fit(boot)\n",
        "    predicted = boot_model.predict(MD_x)\n",
        "\n",
        "    for s in range(4):\n",
        "        ref_binary = (ref_labels == s).astype(int)\n",
        "        pred_binary = (predicted == s).astype(int)\n",
        "        ari = adjusted_rand_score(ref_binary, pred_binary)\n",
        "        segment_stability[s].append(ari)\n",
        "\n",
        "# Boxplot\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.boxplot([segment_stability[i] for i in range(4)], labels=[1, 2, 3, 4])\n",
        "plt.ylim(0, 1)\n",
        "plt.title(\"A.6 – Segment Level Stability Within Solutions (SLSW, k = 4)\")\n",
        "plt.xlabel(\"Segment Number\")\n",
        "plt.ylabel(\"Segment Stability (ARI)\")\n",
        "plt.grid(axis='y')\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "id": "lGKDpn9vofcQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Selection using Information Criteria (AIC, BIC, ICL) for Gaussian Mixture Models"
      ],
      "metadata": {
        "id": "Cx_E0mSL21Og"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.mixture import GaussianMixture\n",
        "\n",
        "aic_scores = []\n",
        "bic_scores = []\n",
        "icl_scores = []\n",
        "gmm_models = {}\n",
        "\n",
        "for k in range(2, 9):\n",
        "    gmm = GaussianMixture(n_components=k, covariance_type='diag', n_init=10, random_state=42)\n",
        "    gmm.fit(MD_x)\n",
        "\n",
        "    # Store models and scores\n",
        "    gmm_models[k] = gmm\n",
        "    aic_scores.append(gmm.aic(MD_x))\n",
        "    bic_scores.append(gmm.bic(MD_x))\n",
        "\n",
        "    # ICL ≈ BIC - entropy (we approximate entropy from posterior probs)\n",
        "    probs = gmm.predict_proba(MD_x)\n",
        "    entropy = -np.sum(probs * np.log(probs + 1e-10))  # Add small value to avoid log(0)\n",
        "    icl_scores.append(bic_scores[-1] + entropy)"
      ],
      "metadata": {
        "id": "2rfhmObzgekf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k_range = range(2, 9)\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(k_range, aic_scores, marker='o', label='AIC', color='blue')\n",
        "plt.plot(k_range, bic_scores, marker='s', label='BIC', color='red')\n",
        "plt.plot(k_range, icl_scores, marker='^', label='ICL', color='green')\n",
        "\n",
        "plt.title(\"A.7 – Information Criteria for Mixture Models\")\n",
        "plt.xlabel(\"Number of Components\")\n",
        "plt.ylabel(\"Value of Information Criteria\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "id": "lqZ6Nr7uo-V8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comparing K-Means and Gaussian Mixture Models (GMM) for k = 4"
      ],
      "metadata": {
        "id": "oVsLLtbk3Cw0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Fit k-means with 4 clusters\n",
        "kmeans_k4 = KMeans(n_clusters=4, n_init=10, random_state=42)\n",
        "kmeans_k4.fit(MD_x)\n",
        "df['kmeans_seg'] = kmeans_k4.labels_\n",
        "\n",
        "# Step 2: Fit GMM with 4 components (random init, 10 restarts)\n",
        "gmm_k4 = GaussianMixture(n_components=4, covariance_type='diag', n_init=10, random_state=42)\n",
        "gmm_k4.fit(MD_x)\n",
        "df['mixture_seg'] = gmm_k4.predict(MD_x)\n",
        "\n",
        "# Step 3: Show cross-tabulation between k-means and mixture segments\n",
        "print(\"Contingency Table: K-means vs Mixture (Random Init)\")\n",
        "cross_tab = pd.crosstab(df['kmeans_seg'], df['mixture_seg'],\n",
        "                        rownames=['kmeans'], colnames=['mixture'])\n",
        "print(cross_tab)\n",
        "\n",
        "# Step 4: Fit another GMM (re-initialized by random again, to simulate re-fit)\n",
        "gmm_k4_reinit = GaussianMixture(n_components=4, covariance_type='diag', n_init=10, random_state=123)\n",
        "gmm_k4_reinit.fit(MD_x)\n",
        "df['mixture_reinit'] = gmm_k4_reinit.predict(MD_x)\n",
        "\n",
        "# Step 5: Cross-tab again to compare second GMM vs k-means\n",
        "print(\"\\nContingency Table: K-means vs Mixture (Second Init)\")\n",
        "cross_tab2 = pd.crosstab(df['kmeans_seg'], df['mixture_reinit'],\n",
        "                         rownames=['kmeans'], colnames=['mixture (new)'])\n",
        "print(cross_tab2)\n",
        "\n",
        "# Step 6: Log-likelihood comparison (as in R)\n",
        "loglik_original = gmm_k4.lower_bound_ * len(MD_x)\n",
        "loglik_reinit = gmm_k4_reinit.lower_bound_ * len(MD_x)\n",
        "\n",
        "print(\"\\nLog-Likelihoods:\")\n",
        "print(f\"Mixture (Random Init):     {loglik_original:.2f}\")\n",
        "print(f\"Mixture (Second Init):     {loglik_reinit:.2f}\")\n"
      ],
      "metadata": {
        "id": "htmvAOy7pA6f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Regression Summary per Segment"
      ],
      "metadata": {
        "id": "dt781BPa3VvT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the mapping from string levels to numeric\n",
        "like_map = {\n",
        "    \"I love it!+5\": 5, \"+4\": 4, \"+3\": 3, \"+2\": 2, \"+1\": 1,\n",
        "    \"0\": 0, \"-1\": -1, \"-2\": -2, \"-3\": -3, \"-4\": -4, \"I hate it!-5\": -5\n",
        "}\n",
        "\n",
        "df['Like.n'] = df['Like'].map(like_map)"
      ],
      "metadata": {
        "id": "DFXn8FIppNQZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = MD_x  # already converted Yes/No to 1/0\n",
        "y = df['Like.n']"
      ],
      "metadata": {
        "id": "epx08LmEqZjF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.mixture import GaussianMixture\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# Step 1: Prepare data\n",
        "X = df.iloc[:, :11].applymap(lambda x: 1 if x == \"Yes\" else 0)\n",
        "y = df['Like.n']\n",
        "data_combined = np.column_stack((y, X))\n",
        "\n",
        "# Step 2: Run GMM on [y|X]\n",
        "gmm_reg = GaussianMixture(n_components=2, n_init=10, covariance_type='full', random_state=42)\n",
        "gmm_reg.fit(data_combined)\n",
        "df['reg_mix_seg'] = gmm_reg.predict(data_combined)\n",
        "\n",
        "# Step 3: Fit OLS regressions per segment\n",
        "coefs, conf_ints, p_values = [], [], []\n",
        "\n",
        "for seg in sorted(df['reg_mix_seg'].unique()):\n",
        "    X_seg = X[df['reg_mix_seg'] == seg]\n",
        "    y_seg = y[df['reg_mix_seg'] == seg]\n",
        "    X_seg_const = sm.add_constant(X_seg)\n",
        "\n",
        "    model = sm.OLS(y_seg, X_seg_const).fit()\n",
        "\n",
        "    coefs.append(model.params)\n",
        "    conf_ints.append(model.conf_int())\n",
        "    p_values.append(model.pvalues)\n",
        "\n",
        "# Step 4: Get common aligned index including 'const'\n",
        "attributes = coefs[0].index.tolist()\n",
        "segments = ['Segment 1', 'Segment 2']\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 6), sharey=True)\n",
        "\n",
        "for i in range(2):\n",
        "    # Align everything using index\n",
        "    coefs_i = coefs[i].reindex(attributes)\n",
        "    ci_i = conf_ints[i].reindex(attributes)\n",
        "    pvals_i = p_values[i].reindex(attributes)\n",
        "\n",
        "    # CI error bars\n",
        "    lower_err = coefs_i - ci_i[0]\n",
        "    upper_err = ci_i[1] - coefs_i\n",
        "    xerr = np.vstack([lower_err, upper_err])\n",
        "\n",
        "    # Significance color\n",
        "    colors = ['darkgrey' if p < 0.05 else 'lightgrey' for p in pvals_i]\n",
        "\n",
        "    # Plot\n",
        "    axes[i].barh(attributes, coefs_i, xerr=xerr, color=colors, edgecolor='black')\n",
        "    axes[i].set_title(segments[i])\n",
        "    axes[i].axvline(0, color='black', lw=0.8)\n",
        "    axes[i].invert_yaxis()\n",
        "\n",
        "fig.suptitle(\"A.8 – Regression Coefficients by Segment (Mixture of Regressions)\", fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VN3Kg4Mr625j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Segment Profile Plot (Ordered by Attribute Clustering)"
      ],
      "metadata": {
        "id": "l0zZYghm7__B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.cluster.hierarchy import linkage, dendrogram\n",
        "from scipy.spatial.distance import pdist\n",
        "import numpy as np\n",
        "\n",
        "# Transpose MD_x so that clustering is done on attributes\n",
        "attr_dist = pdist(MD_x.T, metric='euclidean')\n",
        "linkage_matrix = linkage(attr_dist, method='ward')\n",
        "\n",
        "# Get order of attributes from dendrogram\n",
        "dendro = dendrogram(linkage_matrix, no_plot=True)\n",
        "ordered_attributes = [MD_x.columns[i] for i in dendro['leaves']]"
      ],
      "metadata": {
        "id": "AGspRkuFqjQR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "segment_profiles = MD_x.copy()\n",
        "segment_profiles['segment'] = df['kmeans_seg']\n",
        "\n",
        "# Calculate mean (i.e., % Yes) by segment\n",
        "means_by_segment = segment_profiles.groupby('segment').mean().T  # shape: attributes x segments\n",
        "\n",
        "# Calculate overall means\n",
        "overall_means = MD_x.mean()"
      ],
      "metadata": {
        "id": "KG30KKnZstxH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --- Marker Condition Function ---\n",
        "def is_marker(attr, seg_val, overall_val):\n",
        "    abs_diff = abs(seg_val - overall_val)\n",
        "    rel_diff = abs_diff / (overall_val + 1e-10)\n",
        "    return abs_diff > 0.25 or rel_diff > 0.5\n",
        "\n",
        "# --- Setup ---\n",
        "plt.figure(figsize=(11, 7))\n",
        "bar_height = 0.18\n",
        "colors = ['tab:blue', 'tab:orange', 'tab:green', 'tab:red']  # fixed color map\n",
        "segments = range(4)\n",
        "\n",
        "# --- Draw bars manually for full control ---\n",
        "for seg in segments:\n",
        "    values = means_by_segment.loc[ordered_attributes, seg]\n",
        "    y_base = np.arange(len(ordered_attributes)) + seg * bar_height\n",
        "\n",
        "    for i, attr in enumerate(ordered_attributes):\n",
        "        seg_val = values[attr]\n",
        "        overall_val = overall_means[attr]\n",
        "        color = colors[seg] if is_marker(attr, seg_val, overall_val) else 'lightgrey'\n",
        "\n",
        "        plt.barh(\n",
        "            y=y_base[i],\n",
        "            width=seg_val,\n",
        "            height=bar_height,\n",
        "            color=color,\n",
        "            edgecolor=\"none\"\n",
        "        )\n",
        "\n",
        "# --- Plot overall population reference lines ---\n",
        "for i, attr in enumerate(ordered_attributes):\n",
        "    plt.plot(\n",
        "        [overall_means[attr]]*2,\n",
        "        [i - 0.1, i + bar_height * len(segments)],\n",
        "        color='black', linestyle='--', linewidth=0.7\n",
        "    )\n",
        "\n",
        "# --- Final plot settings ---\n",
        "plt.yticks(np.arange(len(ordered_attributes)) + bar_height * 1.5, ordered_attributes)\n",
        "plt.xlabel(\"Proportion Saying 'Yes'\")\n",
        "plt.title(\"A.9 – Segment Profile Plot (Ordered Attributes)\")\n",
        "legend_patches = [plt.Line2D([0], [0], color=c, lw=10, label=f'Segment {i+1}') for i, c in enumerate(colors)]\n",
        "plt.legend(handles=legend_patches, loc='lower right')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TPMDAN1nswfl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Segment Separation Plot with PCA + Attribute Arrows"
      ],
      "metadata": {
        "id": "wxIlDJ7-8KBq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 1: Projected PCA coords already stored in `pca_coords`\n",
        "df['PC1'] = pca_coords[:, 0]\n",
        "df['PC2'] = pca_coords[:, 1]\n",
        "\n",
        "# Segment labels assumed to be in: df['kmeans_seg'] (0-based)\n",
        "segment_labels = df['kmeans_seg'].unique()\n",
        "colors = ['tab:blue', 'tab:orange', 'tab:green', 'tab:red']  # One color per segment\n",
        "\n",
        "# Step 2: Create combined plot\n",
        "fig, ax = plt.subplots(figsize=(9, 7))\n",
        "\n",
        "# Plot data points colored by segment\n",
        "for seg in segment_labels:\n",
        "    segment_data = df[df['kmeans_seg'] == seg]\n",
        "    ax.scatter(segment_data['PC1'], segment_data['PC2'],\n",
        "               alpha=0.6, label=f\"Segment {seg+1}\", color=colors[seg])\n",
        "\n",
        "    # Plot segment centers\n",
        "    center_x = segment_data['PC1'].mean()\n",
        "    center_y = segment_data['PC2'].mean()\n",
        "    ax.text(center_x, center_y, str(seg+1), fontsize=14,\n",
        "            ha='center', va='center', color='black',\n",
        "            bbox=dict(facecolor='white', edgecolor='black', boxstyle='circle'))\n",
        "\n",
        "# Step 3: Add PCA attribute arrows\n",
        "for i, var in enumerate(MD_x.columns):\n",
        "    ax.arrow(0, 0,\n",
        "             pca.components_[0, i]*2, pca.components_[1, i]*2,\n",
        "             color='darkred', alpha=0.8, head_width=0.03)\n",
        "    ax.text(pca.components_[0, i]*2.3, pca.components_[1, i]*2.3,\n",
        "            var, color='darkred', ha='center', va='center', fontsize=9)\n",
        "\n",
        "# Plot formatting\n",
        "ax.axhline(0, color='black', lw=0.5)\n",
        "ax.axvline(0, color='black', lw=0.5)\n",
        "ax.set_xlabel(\"Principal Component 1\")\n",
        "ax.set_ylabel(\"Principal Component 2\")\n",
        "ax.set_title(\"A.10 – Segment Separation Plot with Attribute Arrows\")\n",
        "ax.grid(True)\n",
        "ax.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UL3SWr7ks8Rz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mosaic Plot: Segment vs Liking McDonald’s"
      ],
      "metadata": {
        "id": "Yiz_YNub8YXY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.graphics.mosaicplot import mosaic\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df['segment'] = df['kmeans_seg'] + 1\n",
        "\n",
        "# Convert Like.n to label\n",
        "like_labels = {\n",
        "    -5: \"Hate(-5)\", -4: \"-4\", -3: \"-3\", -2: \"-2\", -1: \"-1\",\n",
        "     0: \"0\", 1: \"+1\", 2: \"+2\", 3: \"+3\", 4: \"+4\", 5: \"Love(+5)\"\n",
        "}\n",
        "df['Like.cat'] = df['Like.n'].map(like_labels)\n",
        "\n",
        "# Create mosaic plot\n",
        "plt.figure(figsize=(12, 10))\n",
        "mosaic(df, ['segment', 'Like.cat'], title='A.11 – Like vs Segment (Mosaic)', gap=0.01)\n",
        "plt.xlabel(\"Segment Number\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DfCuIajrvHYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mosaic Plot: Segment vs Gender"
      ],
      "metadata": {
        "id": "JGjcKrIK8ghh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['segment'] = df['kmeans_seg'] + 1\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "mosaic(df, ['segment', 'Gender'], title='A.12 – Gender vs Segment (Mosaic)', gap=0.01)\n",
        "plt.xlabel(\"Segment Number\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ECa-GABrvKcP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parallel Boxplot: Age Distribution by Segment"
      ],
      "metadata": {
        "id": "pQb9YRpI9VnV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.boxplot(x=\"segment\", y=\"Age\", data=df, notch=True, width=0.5)\n",
        "plt.title(\"A.13 – Age Distribution by Segment\")\n",
        "plt.xlabel(\"Segment Number\") uu\n",
        "plt.ylabel(\"Age\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dH7bC3QdvSnK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Decision Tree: Predicting Segment 3 Membership"
      ],
      "metadata": {
        "id": "5wJxVhqM9csm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "\n",
        "# Target: is this person in segment 3?\n",
        "df['is_seg3'] = (df['kmeans_seg'] == 2).astype(int)\n",
        "\n",
        "# Encode VisitFrequency as categorical codes\n",
        "df['VisitFreq_code'] = df['VisitFrequency'].astype('category').cat.codes\n",
        "df['Gender_code'] = df['Gender'].astype('category').cat.codes\n",
        "\n",
        "# Features\n",
        "X = df[['Like.n', 'Age', 'VisitFreq_code', 'Gender_code']]\n",
        "y = df['is_seg3']\n",
        "\n",
        "# Train tree\n",
        "clf = DecisionTreeClassifier(max_depth=4, random_state=42)\n",
        "clf.fit(X, y)\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(12, 6))\n",
        "plot_tree(clf, feature_names=X.columns, class_names=[\"Not Seg3\", \"Seg3\"], filled=True)\n",
        "plt.title(\"A.14 – Decision Tree: Who Belongs to Segment 3?\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NymZy9_vvYXg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Segment Evaluation Plot"
      ],
      "metadata": {
        "id": "YdJ2bLzW9vQS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Map VisitFrequency to ordinal scale\n",
        "\n",
        "visit_map = {\n",
        "    \"Never\": 1,\n",
        "    \"Less than once a month\": 2,\n",
        "    \"Once a month\": 3,\n",
        "    \"Every three weeks\": 4,\n",
        "    \"Every two weeks\": 5,\n",
        "    \"Once a week\": 6,\n",
        "    \"Several times a week\": 7\n",
        "}\n",
        "\n",
        "df['VisitFreq_num'] = df['VisitFrequency'].map(visit_map)\n",
        "\n",
        "# Group by segment (1–4)\n",
        "seg_group = df.groupby('segment')\n",
        "\n",
        "# Mean visit frequency\n",
        "visit_means = seg_group['VisitFreq_num'].mean()\n",
        "\n",
        "# Mean Like.n\n",
        "like_means = seg_group['Like.n'].mean()\n",
        "\n",
        "# % Female\n",
        "female_props = seg_group['Gender'].apply(lambda x: (x == \"Female\").mean())\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot setup\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(\n",
        "    visit_means, like_means,\n",
        "    s=female_props * 1000,  # Scale bubble size\n",
        "    alpha=0.6,\n",
        "    edgecolors='black',\n",
        "    c=['tab:blue', 'tab:orange', 'tab:green', 'tab:red']\n",
        ")\n",
        "\n",
        "# Annotate segment numbers\n",
        "for i in range(1, 5):\n",
        "    plt.text(visit_means[i], like_means[i], str(i), fontsize=12, ha='center', va='center')\n",
        "\n",
        "# Axis labels and limits\n",
        "plt.xlim(2, 4.5)\n",
        "plt.ylim(-3, 3)\n",
        "plt.xlabel(\"Mean Visit Frequency (numeric)\")\n",
        "plt.ylabel(\"Mean Like Score (-5 to +5)\")\n",
        "plt.title(\"A.15 – Segment Evaluation Plot\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "d6qGgyuNvfYZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}